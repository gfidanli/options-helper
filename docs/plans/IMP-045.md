# IMP-045 — Live 0DTE Monitor Mode (Streaming + Auto-Refreshing Dashboard)

- **Status:** draft
- **Effort:** L
- **Alpha potential:** High

## Summary
Build an optional live-monitor workflow where users can run Alpaca streaming capture, continuously rescore 0DTE put conditions with a frozen model, and watch a single Streamlit screen update with freshness/health guardrails. This is decision support only and **not financial advice**.

## Goals
- Provide near-real-time updates for the **Current State Probability** panel from streaming/intraday data.
- Keep model usage causal:
  - training remains batch/offline,
  - live scoring uses a frozen active model only.
- Surface clear operational health on the dashboard:
  - data freshness,
  - stream status,
  - scoring lag,
  - stale/fallback warnings.
- Reuse existing ingestion/streaming/scoring code paths where possible.

## Non-goals
- Auto-trading, order routing, or broker execution integration.
- Replacing batch study/backtest workflows.
- Guaranteeing complete historical reconstruction from snapshot endpoints.
- Removing existing read-only dashboard behavior for non-live users.

## User-facing changes
- New CLI workflow to run live monitor scoring loop (proposed):
  - `options-helper market-analysis zero-dte-put-live-monitor ...`
- Optional dashboard "Live Mode" in 0DTE Put Study page:
  - auto-refresh cadence control,
  - health banner + freshness badges,
  - latest scored decision cards/table.
- New docs/runbook for safe operation and limitations.

## Design
### Inputs
- Streaming/intraday partitions under `data/intraday/` (existing stream capture pipeline).
- Daily snapshots/candles caches (`data/options_snapshots`, `data/candles`).
- Frozen active model artifact:
  - `data/reports/zero_dte_put_study/{SYMBOL}/active_model.json`.

### Outputs / schemas
- New live-monitor artifact (append/update, deterministic keying) under:
  - `data/reports/zero_dte_put_study/{SYMBOL}/live_monitor.jsonl`
  - optional compact latest-state file:
    - `data/reports/zero_dte_put_study/{SYMBOL}/live_state.json`
- Row schema should include:
  - anchor fields (`session_date`, `decision_ts`, `entry_anchor_ts`),
  - score fields (`risk_tier`, `strike_return`, `breach_probability`, CI),
  - policy fields (`policy_status`, `policy_reason`, `ladder_rank`),
  - health fields (`stream_lag_seconds`, `data_freshness_seconds`, `scoring_latency_ms`, `stale_flag`),
  - model provenance (`model_version`, `assumptions_hash`, `trained_through_session`).

### Key algorithms / heuristics
- Run a bounded loop (for example every 5-15 seconds):
  - read latest available intraday/snapshot state,
  - construct causal candidate row(s),
  - score via frozen model,
  - upsert by deterministic forward key fields.
- Freshness gating:
  - if freshness/lag exceeds threshold, mark rows as stale and suppress "favorable" highlighting.
- Fallback transparency:
  - persist explicit fallback reasons rather than silent behavior.
- Keep anti-lookahead invariants aligned with existing 0DTE assumptions.

## Implementation plan
### Step 1 — Define live artifact contract + persistence helpers
**Files:**
- `options_helper/schemas/zero_dte_put_study.py`
- `options_helper/data/zero_dte_artifacts.py`
- `tests/test_zero_dte_artifacts.py`

**Work:**
- Add typed schema for live monitor rows + latest state payload.
- Add append/upsert helpers with deterministic keys and idempotent writes.
- Add parser/backward-compat helpers for future schema evolution.

### Step 2 — Build incremental live scoring service
**Files:**
- `options_helper/analysis/zero_dte_live_monitor.py` (new)
- `options_helper/commands/market_analysis.py`
- `tests/test_zero_dte_live_monitor.py` (new)

**Work:**
- Implement loop service that loads frozen model, scores latest state, and writes live artifacts.
- Reuse existing candidate construction/scoring primitives from zero-dte study/forward workflows.
- Add stop conditions and graceful shutdown behavior.

### Step 3 — Integrate stream capture status + health metadata
**Files:**
- `options_helper/data/streaming/runner.py`
- `options_helper/commands/stream.py`
- `tests/test_stream_runner.py` (extend)

**Work:**
- Expose lightweight runtime metrics for stream health:
  - last event ts per dataset/symbol,
  - reconnect counts,
  - queue depth / flush age.
- Make these metrics readable by live monitor scorer for freshness gating.

### Step 4 — Add CLI command for live monitor operation
**Files:**
- `options_helper/commands/market_analysis.py`
- `tests/test_zero_dte_cli.py`

**Work:**
- Add `zero-dte-put-live-monitor` command with flags for:
  - symbol,
  - polling cadence,
  - stale thresholds,
  - output paths,
  - max runtime (optional).
- Fail clearly when active model is missing or stale relative to session.

### Step 5 — Streamlit live mode UX
**Files:**
- `apps/streamlit/components/zero_dte_put_page.py`
- `apps/streamlit/pages/11_0DTE_Put_Study.py`
- `tests/portal/test_zero_dte_put_page.py`

**Work:**
- Add optional live mode toggle (default off).
- Add auto-refresh and a single-screen "now" view:
  - current scored rows,
  - health/freshness banners,
  - last update timestamp.
- Keep existing read-only artifact views intact.

### Step 6 — Ops docs and safety runbook
**Files:**
- `docs/SPXW_0DTE_PUT_STUDY.md`
- `docs/PORTAL_STREAMLIT.md`
- `docs/INGEST.md`

**Work:**
- Document required processes, cadence, and failure modes.
- Document explicit limitations:
  - live decision support only,
  - no execution automation,
  - endpoint coverage/latency caveats.

## Tests
- Unit tests:
  - live row keying/idempotency,
  - stale/fresh gating,
  - fallback reason persistence.
- CLI tests:
  - command argument validation and missing-model errors.
- Streamlit tests:
  - live-mode rendering and stale-state banners.
- Deterministic fixtures only; no network calls in tests.

## Acceptance criteria
- User can run a single live-monitor command and see continuously updated 0DTE live scores in Streamlit.
- Dashboard clearly indicates freshness and stream/scoring health.
- Live scoring remains causally correct with frozen-model-only inference.
- Existing batch study/forward workflows remain unchanged and passing.
- Docs clearly state operational setup and non-advisory constraints.

## Open questions
- Preferred default refresh cadence for UX vs compute load.
- Whether to persist all ticks/updates or only decision-time checkpoints in `live_monitor.jsonl`.
- Whether to gate "favorable" highlighting behind a minimum freshness + quality threshold policy.
