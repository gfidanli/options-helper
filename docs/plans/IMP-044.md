# IMP-044 — DuckDB warehouse resilience: audit, path portability, and compaction

- **Status:** draft
- **Effort:** M–L
- **Alpha potential:** Medium

## Summary
The current DuckDB warehouse is functionally correct but operationally inefficient for high-churn write paths.
Recent inspection shows large file growth relative to live row counts, stale snapshot path pointers, and mixed
test-like artifacts in the working warehouse. This IMP hardens DuckDB usage so backtests/analytics stay fast and
predictable as data volume grows.

## Current state (what exists today)
- CLI already ships `options-helper db init/info/health`.
- Coverage diagnostics exist via `options-helper coverage SYMBOL` (DuckDB-first, read-only).
- Snapshot headers (`options_snapshot_headers`) persist `chain_path/meta_path/raw_path` strings; these can become
  stale when snapshot files move, and `list_dates()` can currently report dates even when the backing files are missing.
- Observability run logging (`DuckDBRunLogger`) writes many small transactions (per asset/check/watermark), which
  amplifies file growth on long-running ingest/backtest workflows.

## Goals
- Reduce warehouse bloat by decreasing:
  - per-event transactions (batch/flush),
  - delete+insert churn where `ON CONFLICT ... DO UPDATE` is available,
  - stale header rows pointing to missing lake files.
- Make snapshot header path references portable across workspaces (relative paths) while still preventing cross-root
  contamination.
- Add first-class maintenance workflows for compaction and health auditing.
- Prevent test/dev data from contaminating the primary working warehouse.
- Preserve existing CLI behavior and read compatibility during migration.

## Non-goals
- Replacing the current intraday partitioned file store in this IMP.
- Reworking strategy/backtest logic or signal semantics.
- Migrating to a remote database service.

## User-facing changes
- Extend existing `options-helper db` command group:
  - keep `db health` (observability summary)
  - add `db audit` (physical DB + snapshot integrity + key table stats; JSON-friendly output)
  - add `db compact` (safe reclaim of space + optional backup)
- Snapshot metadata remains queryable the same way, but new writes additionally store stable relative paths.
- Clear operational doc/runbook for DuckDB upkeep (including locks + backups).

## Design
### Constraints / risks
- DuckDB is embedded: assume **single writer**. `db compact` requires exclusive access to the target file.
- Streamlit/Dagster may hold read-only connections; maintenance commands should surface actionable “close other
  processes / switch to filesystem backend” guidance instead of crashing.

### Inputs
- Existing warehouse file (`data/warehouse/options.duckdb`)
- Existing schema + migrations (`options_helper/db/schema_v*.sql`)
- Existing stores/loggers:
  - `options_helper/data/stores_duckdb.py`
  - `options_helper/data/observability_meta.py`
- Existing diagnostics helpers (reuse where possible):
  - `options_helper/data/coverage_duckdb.py`
  - `options_helper/data/coverage_service.py`

### Outputs / schemas
- New migration version (proposed v6) for `options_snapshot_headers`:
  - Add nullable `chain_path_rel/meta_path_rel/raw_path_rel` columns (paths relative to `lake_root`).
  - Add `lake_root_hint` (string) to preserve the existing cross-root safety guard when relative paths are used.
- Backward-compatible read path:
  - Prefer relative fields when present *and* `lake_root_hint` matches current `lake_root` config *and* the file exists.
  - Fall back to legacy absolute fields when present and under the active `lake_root`.
  - Ignore header rows whose resolved files are missing; let `db audit` report and suggest repair.

### Key algorithms / heuristics
- **Audit (read-only):**
  - File size + schema version.
  - Row counts and “latest updated_at” per high-churn table (`meta.*`, `options_snapshot_headers`, …).
  - Snapshot header integrity: missing Parquet/meta/raw files; headers outside active lake root; headers with zero
    contracts.
  - Emit optional “repair suggestions” (copy/paste CLI commands) similar to `coverage`.
- **Observability write shaping:**
  - Batch per-run asset/check/watermark writes instead of tiny per-event transactions.
  - Flush at run end and at bounded batch thresholds; if a flush fails, fall back to best-effort single writes.
- **Compaction strategy (copy/swap):**
  1. Acquire application-level maintenance lock.
  2. Create new DuckDB file; run migrations to create schema/indexes.
  3. Copy live tables into the fresh file in one pass.
  4. Validate table counts (and optional checksums) per table.
  5. Swap files atomically (keep timestamped backup).
- **Upsert churn reduction:**
  - Replace `DELETE` + `INSERT` patterns with `INSERT ... ON CONFLICT DO UPDATE` where possible (notably
    `options_snapshot_headers` and `derived_daily`).

## Implementation plan
### Step 1 — Baseline + `db audit`
**Files:**
- `options_helper/commands/db.py`
- `options_helper/data/duckdb_audit.py` (new)
- `tests/test_db_health_cli.py` (extend) and/or `tests/test_duckdb_cli_db.py` (extend)

**Work:**
- Implement audit helpers for:
  - file size,
  - schema version,
  - row counts,
  - missing snapshot lake files (parquet/meta/raw),
  - summary reuse of existing `coverage` + `db health` queries where helpful.
- Expose as `options-helper db audit [--json] [--out PATH]`.

### Step 2 — Environment isolation guardrails
**Files:**
- `options_helper/data/store_factory.py`
- `options_helper/data/storage_runtime.py`
- `tests/conftest.py` (new, autouse) or targeted fixtures in existing tests

**Work:**
- Add a test-time guard to ensure no test writes to `data/warehouse/options.duckdb` by default.
- Clear/close cached warehouses between tests to avoid cross-test state leakage.
- Document recommended dev workflows:
  - set `--duckdb-path` explicitly for experiments,
  - use `--storage filesystem` when DuckDB is locked by a running Streamlit portal.

### Step 3 — Snapshot header path migration (portable paths)
**Files:**
- `options_helper/db/schema_v6.sql` (new)
- `options_helper/db/migrations.py`
- `options_helper/data/stores_duckdb.py`
- `tests/test_duckdb_migrations_v2.py` (extend for v6)
- `tests/test_duckdb_options_snapshot_store.py` (extend)

**Work:**
- Add new relative-path columns + optional root hint.
- Update snapshot store header upsert to:
  - write absolute legacy fields (status quo),
  - write relative fields + root hint for new rows,
  - use `ON CONFLICT ... DO UPDATE` instead of delete/insert.
- Update reads/listing to ignore header rows whose files are missing; prefer relative-first resolution.
- Add `db audit` “repair suggestions” for rows with stale absolute paths (optionally a `db repair-snapshot-paths`
  subcommand if needed).

### Step 4 — Write-path batching for observability + churn cleanup
**Files:**
- `options_helper/data/observability_meta.py`
- `options_helper/data/stores_duckdb.py`
- `tests/test_observability_meta.py`
- `tests/test_command_run_ledger_instrumentation.py`

**Work:**
- Introduce buffered/batched write mode for run assets, checks, and watermarks.
- Keep API-compatible semantics (`log_*` remains available), but reduce transaction count.
- Ensure flush-on-finalize and crash-safe behavior.
- Switch remaining `DELETE`+`INSERT` upserts (e.g. `derived_daily`) to `ON CONFLICT` upsert forms.

### Step 5 — Safe compaction command
**Files:**
- `options_helper/commands/db.py`
- `options_helper/data/duckdb_compact.py` (new)
- `tests/test_duckdb_cli_db.py` (extend) and/or `tests/test_db_compact_cli.py` (new)
- `docs/DUCKDB_OPERATIONS.md` (new)

**Work:**
- Implement `db compact` with:
  - dry-run mode,
  - backup retention option,
  - post-compact verification.
- Add explicit lock/error messaging when the source DB is in use.
- Document when to run it, expected disk needs, and rollback guidance.

## Tests
- Migration tests covering v6 forward compatibility and idempotency.
- Snapshot store tests for relative-path write/read, missing-file filtering, and legacy fallback.
- Observability tests validating batched writes preserve final table state.
- CLI tests for `db audit` and `db compact` output (JSON + non-JSON).

## Acceptance criteria
- `options-helper db audit --json` provides a stable payload usable by automations.
- `db audit` flags missing/stale snapshot header paths and suggests repairs.
- New snapshot header rows store portable relative paths without reintroducing cross-root contamination.
- Compaction workflow is deterministic and validated by integration tests.
- On a churn-heavy fixture, `db compact` reduces file size measurably and preserves row counts exactly.
- No regression in existing ingestion/snapshot command behavior (`pytest` targeted suites pass).
