# IMP-003 — Explainable confluence/conviction score

- **Status:** done
- **Effort:** M
- **Alpha potential:** Med–High

## Summary
Create a single, explainable “confluence” score that blends technical direction, flow alignment, and volatility regime context. Use it to rank research ideas and scanner candidates while keeping the underlying components transparent.

## Goals
- Produce a `ConfluenceScore` object with:
  - total score (0–100)
  - component contributions and weights
  - human-readable reasons
- Inputs (v1):
  - weekly trend state (up/down/flat)
  - extension percentile (tail vs neutral)
  - RSI divergence flags
  - flow alignment (ΔOI notional direction vs trend)
  - IV regime (IV/RV)
- Use in:
  - `research` ranking (primary)
  - scanner shortlist ranking (secondary)
  - briefing JSON (visibility)

## Non-goals
- Machine learning models.
- Any claim that a score predicts returns.

## User-facing changes
- Research output includes:
  - `confluence_score`
  - a short “components” breakdown
- Scanner shortlist sorted by the score (when all inputs are available).

## Design
### Scoring principles
- Missing inputs should degrade gracefully:
  - compute score from available components
  - track `coverage` (0–1) and show it
- Keep weights in config so you can tune without code changes.

### Example component mapping (v1)
- Weekly trend: +25 supportive / -25 adverse
- Extension percentile:
  - tail aligned with trend: +10
  - tail against trend: -10
- Flow alignment:
  - aligned: +20
  - conflicting: -20
- RSI divergence:
  - divergence against trend: -10
  - divergence in favor: +5
- IV regime:
  - high IV/RV: +5 (context only)
  - low IV/RV: -5

(Exact values TBD; start simple and iterate via IMP-006 journal.)

## Implementation plan
### Step 1 — Define a model + pure scorer
**Files:**
- `options_helper/analysis/confluence.py` (new)

**Work:**
- Define pydantic models:
  - `ConfluenceComponent(name, weight, value, score, reason)`
  - `ConfluenceScore(total, coverage, components, warnings)`
- Implement `score_confluence(inputs, cfg) -> ConfluenceScore`.

### Step 2 — Add config defaults
**Files:**
- `config/confluence.yaml` (new) OR embed under existing config
- optional schema json

**Work:**
- Provide default weights/thresholds.

### Step 3 — Integrate into research
**Files:**
- `options_helper/analysis/research.py`

**Work:**
- Compute input components per symbol (using existing technical snapshots / derived / flow if present).
- Use `total` to sort within the watchlist.

### Step 4 — Integrate into scanner
**Files:**
- `options_helper/data/scanner.py`

**Work:**
- When technical snapshot exists, compute partial confluence and include in shortlist output.

### Step 5 — Surface in briefing JSON
**Files:**
- `options_helper/reporting_briefing.py`

### Step 6 — Tests
**Files:**
- `tests/test_confluence_score.py` (new)

**Work:**
- Unit tests for deterministic scoring.
- Golden JSON output for a known input.

## Acceptance criteria
- Research results display a confluence score and components.
- Score is explainable, deterministic, and robust to missing data.
